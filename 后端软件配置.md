# 后端软件配置

## 1.mysql

```
UPDATE mysql.user SET Host='%' WHERE User='root';
FLUSH PRIVILEGES;
```

启动docker容器访问 不只是localhost可以

如果显示`Public Key Retrieval is not allowed`

```
spring.datasource.url=jdbc:mysql://localhost:3306/your_database?allowPublicKeyRetrieval=true
```

在database名称?xxx&xxx&加上allowPublicKeyRetrieval=true

## 2.nexus

首先进入`C:\Software\DevelopmentTool\BuildTool\nexus-3.75.1-01\bin`

安装

```
nexus.exe /install
```

![image-20250121220325158](https://s2.loli.net/2025/01/21/waYDJTxdK5NECGV.png)

```
nexus.exe /start 启动
nexus.exe /restart 重启
nexus.exe /status  查看状态
nexus.exe /stop  停止
```

![image-20250121220346312](https://s2.loli.net/2025/01/21/oMXQghjvBGxWaFY.png)

登录网址`http://localhost:8081/` 点击右上角Sign in 弹出的窗口显示初始密码所在处

第一次登陆后会配置admin密码 `123123` 以及是否允许匿名访问

## 3.nexus-maven

打开maven的配置文件

首先进入`C:\Software\DevelopmentTool\BuildTool\apache-maven-3.9.9\conf`打开settings.xml

在mirror子标签配置nexus仓库地址`http://localhost:8081/repository/maven-public/`

![image-20250121220413600](https://s2.loli.net/2025/01/21/dtqTZPbaUOCNmEy.png)

``````xml
<mirror>
	<id>maven-nexus</id>
	<mirrorOf>central</mirrorOf>
	<name>nexus私服</name>
	<url>http://localhost:8081/repository/maven-public/</url>
</mirror>
``````

再在server子标签配置用户名与密码

```xml
<server>
	<id>maven-nexus</id>
	<username>admin</username>
	<password>123123</password>
</server>
```

## 4.git

安装一路默认next

配置主机的SSH密钥绑定GitHub账号 Settings -> SSH keys

在C:\Users\11965下输入

```
ssh-keygen -t rsa -b 4096
```

后续回车直至密钥生成

密钥生成后打开.ssh文件夹下的id_rsa.pub将里面内容配置到GitHub账号的SSH密钥下 后续可在IDEA中使用Git做版本管理

## 5.node.js

安装一路默认next

安装后通过

```
npm -v
node -v
```

查看是否配好

在安装路径的根目录下新建两个文件夹，node_cache和node_global 文件夹权限开启完全访问

配置缓存目录和全局目录

```
npm config set cache "C:\Program Files\nodejs\node_cache"
npm config set prefix "C:\Program Files\nodejs\node_global"
```

通过

```
npm config get prefix 
npm config get cache 
```

查看是否配好

配置国内镜像源

```
npm config set registry http://mirrors.cloud.tencent.com/npm/  
```

查看配置的镜像源

```
npm get registry 
```

## 6.wsl与docker

首先打开开发者选项的开发人员模式

<img src="https://s2.loli.net/2025/01/21/hgZxMRy7cbve2nN.png" alt="image-20250121220429711" style="zoom:50%;" />

找到控制面板 -> 程序和功能 -> 启用或关闭Windows功能，选中 适用于Linux的Windows子系统 以及 Virtual Machine Platform，然后点击 确定

<img src="https://s2.loli.net/2025/01/21/6iDaCQgydncWVbP.png" alt="image-20250121220443065" style="zoom:50%;" />

安装wsl

```
wsl --install
```

将wsl2设置为默认版本

```
wsl --set-default-version 2
```

安装docker后配置最新镜像

![image-20250121220504578](https://s2.loli.net/2025/01/21/8Oil3BbZ6SsnLTc.png)

```json
{
  "builder": {
    "gc": {
      "defaultKeepStorage": "20GB",
      "enabled": true
    }
  },
  "experimental": false,
  "registry-mirrors": [
    "https://docker.hpcloud.cloud",
    "https://docker.m.daocloud.io",
    "https://docker.unsee.tech",
    "https://docker.1panel.live",
    "http://mirrors.ustc.edu.cn",
    "https://docker.chenby.cn",
    "http://mirror.azure.cn",
    "https://dockerpull.org",
    "https://dockerhub.icu",
    "https://hub.rat.dev",
    "https://proxy.1panel.live",
    "https://docker.1panel.top",
    "https://docker.m.daocloud.io",
    "https://docker.1ms.run",
    "https://docker.ketches.cn"
  ]
}
```

## 7.docker 镜像与容器

### 7.1 redis

```
docker pull redis

docker run -d -p 6379:6379 -v C:\Data\Redis\data:/data --name redis -e REDIS_PASSWORD=123123 redis --requirepass 123123
```

redis.conf

```
requirepass 123123
```

### 7.2 minio

`-p 9000:9000`: 将容器的 9000 端口映射到宿主机 9000 端口（HTTP）

`-p 9091:9091`: 将容器的 9091 端口映射到宿主机 9091 端口（HTTPS）

```
docker pull minio/minio

docker run -d --name minio -p 9000:9000 -p 9091:9091 -v C:\Data\Minio\data:/data -v C:\Data\Minio\conf:/root/.minio -e MINIO_ROOT_USER=minioadmin -e MINIO_ROOT_PASSWORD=minioadmin -e MINIO_ADDRESS=":9000" -e MINIO_CONSOLE_ADDRESS=":9091" -e MINIO_CORS_ALLOW_ORIGIN="*" minio/minio server /data --console-address ":9091"

```

config.json

```json
{
  "version": "36",
  "credential": {
    "accessKey": "minioadmin",
    "secretKey": "minioadmin"
  },
  "region": "us-east-1",
  "browser": "on",
  "address": ":9000",
  "console_address": ":9091",
  "logger": {
    "console": {
      "enabled": true,
      "level": "info"
    }
  },
  "notify": {
    "webhook": {},
    "amqp": {},
    "kafka": {}
  }
}
```

### 7.3 zipkin

```
docker pull openzipkin/zipkin

docker run -d --name zipkin -p 9411:9411 openzipkin/zipkin
```

### 7.4 nacos

```
docker pull nacos/nacos-server

docker run -d --name nacos -p 8848:8848 -p 9848:9848 -e MODE=standalone -e JVM_XMS=512m -e JVM_XMX=512m -v C:/Data/Nacos/data:/home/nacos/data nacos/nacos-server
```

### 7.5 sentinel

```
docker pull bladex/sentinel-dashboard

docker run -d --name sentinel -p 8858:8858 bladex/sentinel-dashboard
```

### 7.6 seata

必须先启动nacos

```
docker pull seataio/seata-server
```

自定义配置文件需要通过挂载文件的方式实现，将宿主机上的 `application.yml` 挂载到容器中相应的目录

首先启动一个用户将resources目录文件拷出的临时容器

```text
docker run -d -p 8091:8091 -p 7091:7091  --name seata-serve seataio/seata-server:latest
docker cp seata-serve:/seata-server/resources /User/seata/config
```

拷出后可以,可以选择修改application.yml再cp进容器,或者rm临时容器,如下重新创建,并做好映射路径设置

![image-20250121220517899](https://s2.loli.net/2025/01/21/ZGXQ69sPaA1ny4e.png)

```
docker run -d --name seata -p 7091:7091 -p 8091:8091 -v C:/Data/Seata/config:/seata-server/resources -v C:/Data/Seata/logs:/root/logs/seata -e SEATA_CONFIG_NAME=file:/seata-server/resources/application.yml seataio/seata-server:latest
```

Seata需要与Naocs通信，但是他们是属于docker 容器间的通信，所以需要创建通信网络并改变seata的配置文件

```
docker network create seata-network

# 语法
docker network connect [网络名称] [容器名称或ID]

# 示例：将 nacos 容器加入 seata-network
docker network connect seata-network nacos

# 同理，加入其他容器（如 seata、sentinel、mysql）
docker network connect seata-network seata
docker network connect seata-network sentinel
docker network connect seata-network mysql
```

在 Seata 配置中，这部分配置主要用于指定 Seata 服务的集群地址信息。

- **`seata`**：这是 Seata 配置的根节点，表示下面的配置项都是与 Seata 相关的配置。
- **`service`**：用于配置 Seata 服务相关的属性。
- **`default`**：表示默认的服务分组，在 Seata 中可以有多个服务分组，`default` 是其中一个特殊的分组。
- **`grouplist`**：指定了 Seata 服务集群的地址列表。`nacos:8091` 表示 Seata Server 的地址和端口，客户端（微服务）会根据这个地址去连接 Seata Server 进行分布式事务的协调管理。

application.yml

```yml
server:
  port: 7091
spring:
 application:
  name: seata-server
logging:
  config: classpath:logback-spring.xml
  file:
    path: ${log.home:${user.home}/logs/seata}
  extend:
    logstash-appender:
      destination: 127.0.0.1:4560
    kafka-appender:
      bootstrap-servers: 127.0.0.1:9092
      topic: logback_to_logstash
console:
  user:
    username: seata
    password: seata
seata:
  service:
    default:
      grouplist: nacos:8091
  config:
    type: nacos
    nacos:
      server-addr: nacos:8848
      namespace: 
      group: SEATA_GROUP #后续自己在nacos里面新建,不想新建SEATA_GROUP，就写DEFAULT_GROUP
      username: nacos
      password: nacos
  registry:
    type: nacos
    nacos:
      application: seata-server
      server-addr: nacos:8848
      group: SEATA_GROUP #后续自己在nacos里面新建,不想新建SEATA_GROUP，就写DEFAULT_GROUP
      namespace: 
      cluster: default
      username: nacos
      password: nacos    
  store:
    mode: db
    db:
      datasource: druid
      db-type: mysql
      driver-class-name: com.mysql.cj.jdbc.Driver
      url: jdbc:mysql://localhost:3306/seata?characterEncoding=utf8&useSSL=false&serverTimezone=GMT%2B8&rewriteBatchedStatements=true&allowPublicKeyRetrieval=true
      user: root
      password: 123123
      min-conn: 10
      max-conn: 100
      global-table: global_table
      branch-table: branch_table
      lock-table: lock_table
      distributed-lock-table: distributed_lock
      query-limit: 1000
      max-wait: 5000
  #  server:
  #    service-port: 8091 #If not configured, the default is '${server.port} + 1000'
  security:
    secretKey: SeataSecretKey0c382ef121d778043159209298fd40bf3850a017
    tokenValidityInMilliseconds: 1800000
    ignore:
      urls: /,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.jpeg,/**/*.ico,/api/v1/auth/login,/metadata/v1/**
```

springboot的配置

```properties
seata.tx-service-group=daijia_tx_group
seata.service.vgroup-mapping.daijia_tx_group=default
seata.service.grouplist.default=localhost:8091
```

**`seata.tx-service-group=daijia_tx_group`**：

- 这个配置指定了当前 Spring Boot 应用所属的事务服务组名称为 `daijia_tx_group`。在分布式事务中，不同的微服务可以属于不同的事务服务组，用于区分不同的业务模块或者服务集群。

**`seata.service.vgroup-mapping.daijia_tx_group=default`**：

- `vgroup-mapping` 用于建立事务服务组与 Seata Server 分组之间的映射关系。这里表示 `daijia_tx_group` 这个事务服务组映射到 Seata Server 的 `default` 分组。这样，当客户端（Spring Boot 应用）发起分布式事务请求时，会根据这个映射关系找到对应的 Seata Server 分组。

**`seata.service.grouplist.default=192.168.5.7:8091`**：

- 这个配置和前面 YAML 配置中的 `grouplist` 作用类似，指定了 `default` 分组对应的 Seata Server 地址和端口。当客户端通过 `vgroup-mapping` 找到 `default` 分组后，就会使用这个地址去连接 Seata Server。

nacos的配置 在使用 Seata 进行分布式事务管理时，客户端（Spring Boot 应用）需要知道事务服务组（`tx-service-group`）与 Seata Server 分组（`vgroup`）之间的映射关系，这个映射关系就通过 `seata.service.vgroup-mapping` 来配置。而当 Seata 使用 Nacos 作为配置中心时，这些配置信息需要存储在 Nacos 中，客户端会从 Nacos 拉取这些配置。

`service.vgroupMapping` 是 Seata 用来定义事务服务组（`tx-service-group`）和虚拟分组（`vgroup`）映射关系的固定前缀。Seata 客户端在启动时，会按照这个固定的格式去读取对应的配置信息，从而明确该事务服务组要连接到哪个 Seata Server 分组。

比如，在 Nacos 或者其他配置中心里，你若要配置 `daijia_tx_group` 事务服务组对应的 Seata Server 分组，就需要以 `service.vgroupMapping.daijia_tx_group` 作为 `Data ID` 或者配置项的键。

事务服务组名称（如 `daijia_tx_group`）并非固定的，可以根据项目的业务模块、服务集群等情况灵活定义。不同的微服务可以属于不同的事务服务组，这样做有助于对分布式事务进行管理和隔离。

例如，你的项目里有订单服务和库存服务，你可以分别为它们定义不同的事务服务组：

- 订单服务：`seata.tx-service-group=order_tx_group`
- 库存服务：`seata.tx-service-group=inventory_tx_group`

然后在配置中心里分别配置它们和 Seata Server 分组的映射关系：

- `service.vgroupMapping.order_tx_group=order_group`
- `service.vgroupMapping.inventory_tx_group=inventory_group`

Seata Server 分组名称（像 `default`、`order_group`、`inventory_group` 这类）同样可以自定义。不过要保证在 Seata Server 的配置以及客户端的映射配置中保持一致。

例如，在 Seata Server 的配置里，你可以为不同的分组指定不同的 Seata Server 实例地址：

```properties
service.grouplist.order_group=192.168.1.100:8091
service.grouplist.inventory_group=192.168.1.101:8091
```



![{117746D2-7158-415E-940E-0196F7EF88C9}](https://s2.loli.net/2025/02/08/KjAnwaFOqSNPe4D.png)

MySQL查询表单

```sql
-- 创建数据库
CREATE DATABASE IF NOT EXISTS seata DEFAULT CHARSET utf8mb4;
USE seata;
-- global_table 全局事务表
CREATE TABLE IF NOT EXISTS `global_table`
(
    `xid`                       VARCHAR(128) NOT NULL,
    `transaction_id`            BIGINT,
    `status`                    TINYINT      NOT NULL,
    `application_id`            VARCHAR(32),
    `transaction_service_group` VARCHAR(32),
    `transaction_name`          VARCHAR(128),
    `timeout`                   INT,
    `begin_time`               BIGINT,
    `application_data`          VARCHAR(2000),
    `gmt_create`               DATETIME,
    `gmt_modified`             DATETIME,
    PRIMARY KEY (`xid`),
    KEY `idx_status_gmt_modified` (`status`, `gmt_modified`),
    KEY `idx_transaction_id` (`transaction_id`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8mb4;
-- branch_table 分支事务表
CREATE TABLE IF NOT EXISTS `branch_table`
(
    `branch_id`         BIGINT       NOT NULL,
    `xid`              VARCHAR(128)  NOT NULL,
    `transaction_id`    BIGINT,
    `resource_group_id` VARCHAR(32),
    `resource_id`       VARCHAR(256),
    `branch_type`       VARCHAR(8),
    `status`            TINYINT,
    `client_id`         VARCHAR(64),
    `application_data`  VARCHAR(2000),
    `gmt_create`        DATETIME,
    `gmt_modified`      DATETIME,
    PRIMARY KEY (`branch_id`),
    KEY `idx_xid` (`xid`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8mb4;
-- lock_table 全局锁表
CREATE TABLE IF NOT EXISTS `lock_table`
(
    `row_key`        VARCHAR(128) NOT NULL,
    `xid`            VARCHAR(128),
    `transaction_id` BIGINT,
    `branch_id`      BIGINT       NOT NULL,
    `resource_id`    VARCHAR(256),
    `table_name`     VARCHAR(32),
    `pk`             VARCHAR(36),
    `status`         TINYINT      NOT NULL DEFAULT '0',
    `gmt_create`     DATETIME,
    `gmt_modified`   DATETIME,
    PRIMARY KEY (`row_key`),
    KEY `idx_status` (`status`),
    KEY `idx_branch_id` (`branch_id`),
    KEY `idx_xid_and_branch_id` (`xid`, `branch_id`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8mb4;
-- distributed_lock 分布式锁表
CREATE TABLE IF NOT EXISTS `distributed_lock`
(
    `lock_key`   CHAR(20)    NOT NULL,
    `lock_value` VARCHAR(20) NOT NULL,
    `expire`     BIGINT,
    primary key (`lock_key`)
) ENGINE = InnoDB
  DEFAULT CHARSET = utf8mb4;
```

### 7.7 RocketMQ 

```
docker pull apache/rocketmq
docker pull apacherocketmq/rocketmq-dashboard


docker run -d --name rmqnamesrv -p 9876:9876 apache/rocketmq sh mqnamesrv

docker run -d --name rmqbroker -p 10909:10909 -p 10911:10911 -p 10912:10912 -v C:/Data/RocketMQ/broker/logs:/home/rocketmq/logs -v C:/Data/RocketMQ/broker/store:/home/rocketmq/store -e "NAMESRV_ADDR=host.docker.internal:9876" apache/rocketmq sh mqbroker

docker run -d --name rmqdashboard -p 8083:8080 -e "JAVA_OPTS=-Drocketmq.namesrv.addr=host.docker.internal:9876" apacherocketmq/rocketmq-dashboard
```

`-p 9876:9876`: NameServer 的服务端口

`sh mqnamesrv`: 启动 NameServer 服务的命令

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

`-p 10909:10909`: Broker 对外服务的端口

`-p 10911:10911`: Broker 与生产者通信端口

`-p 10912:10912`: Broker 与消费者通信端口

`-v .../logs`: 日志持久化目录

`-v .../store`: 消息存储持久化目录

`-e "NAMESRV_ADDR=rmqnamesrv:9876"`: 指定 NameServer 地址

------------------------------------------------------------------------

`-p 8083:8080`: Web 控制台访问端口

`-e "JAVA_OPTS=-Drocketmq.namesrv.addr=rmqnamesrv:9876"`: 指定 NameServer 地址

---------------------------------------------

启动顺序必须是 namesrv -> broker -> dashboard

### 7.8 RabbitMQ

额外加入rabbitmq_delayed_message_exchange

```
docker pull rabbitmq:3-management

docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 -v C:/Data/RabbitMQ/plugins:/opt/rabbitmq/plugins rabbitmq:3-management

docker exec rabbitmq rabbitmq-plugins enable rabbitmq_delayed_message_exchange


docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3-management
docker cp rabbitmq:/opt/rabbitmq/plugins C:\Data\RabbitMQ\
延迟启动插件https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/releases/tag/v3.12.0 放入plugins文件夹
删除容器 
挂载运行
```

### 7.9 MongoDB

```
docker pull mongo

docker run -d --name mongodb -p 27017:27017 -v C:\Data\MongoDB\data:/data/db --restart unless-stopped mongo:latest

mongodb://root:example@localhost:27017
```

### 7.10 Kafka

```
docker pull bitnami/kafka

docker run -d --name kafka -p 9092:9092 -e KAFKA_CFG_NODE_ID=1 -e KAFKA_CFG_PROCESS_ROLES=controller,broker -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093 -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 -e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 -e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT -e KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER -e ALLOW_PLAINTEXT_LISTENER=yes -v C:/Data/Kafka/data:/bitnami/kafka bitnami/kafka:latest
```

`-p 9092:9092`: 端口映射，把容器的9092端口映射到主机的9092端口

重要的环境变量(-e)：

- `KAFKA_CFG_NODE_ID=1`: 节点ID，单节点设为1

- `KAFKA_CFG_PROCESS_ROLES=controller,broker`: 同时作为控制器和broker

- ```
  KAFKA_CFG_LISTENERS
  ```

  : 监听地址配置

  - PLAINTEXT://:9092 - 客户端连接用
  - CONTROLLER://:9093 - 内部控制用

- `KAFKA_CFG_ADVERTISED_LISTENERS`: 广播给客户端的连接地址

- `ALLOW_PLAINTEXT_LISTENER=yes`: 允许无加密连接

`-v C:/Data/Kafka/data:/bitnami/kafka`: 数据目录映射，把容器内/bitnami/kafka目录映射到本地C:/Data/Kafka/data
## 8.nginx
下载nginx-service.exe
![image.png](https://raw.githubusercontent.com/GQLiu1001/mytc/master/imgPc/20250301215234.png)
运行
```bash
 nginx -t %% 检查语法 %%
```
```bash
nginx-service.exe install
```
conf
```xml
events {

    worker_connections  1024;

}

  

http {

  server {

    listen 3000;

    server_name localhost;

    location /api/ {

      # 代理设置

      proxy_pass http://localhost:8080/api/;

      # 传递重要的请求头

      proxy_set_header Host $host;

      proxy_set_header X-Real-IP $remote_addr;

      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

      proxy_set_header Cookie $http_cookie;

      proxy_set_header satoken $http_satoken;

      # 删除后端可能发送的CORS头

      proxy_hide_header 'Access-Control-Allow-Origin';

      proxy_hide_header 'Access-Control-Allow-Methods';

      proxy_hide_header 'Access-Control-Allow-Headers';

      proxy_hide_header 'Access-Control-Allow-Credentials';

      # 统一添加CORS头 (使用变量避免重复代码)

      set $cors_origin 'http://localhost:5173';

      set $cors_methods 'GET, POST, PUT, DELETE, OPTIONS';

      set $cors_headers 'Content-Type, satoken, Authorization';

      # 传递cookie设置

      proxy_pass_header Set-Cookie;

      # 处理OPTIONS预检请求

      if ($request_method = 'OPTIONS') {

        add_header 'Access-Control-Allow-Origin' $cors_origin always;

        add_header 'Access-Control-Allow-Methods' $cors_methods always;

        add_header 'Access-Control-Allow-Headers' $cors_headers always;

        add_header 'Access-Control-Allow-Credentials' 'true' always;

        add_header 'Access-Control-Expose-Headers' 'satoken' always;

        add_header 'Content-Length' 0;

        return 204;

      }

      # 对所有非OPTIONS请求添加CORS头

      add_header 'Access-Control-Allow-Origin' $cors_origin always;

      add_header 'Access-Control-Allow-Methods' $cors_methods always;

      add_header 'Access-Control-Allow-Headers' $cors_headers always;

      add_header 'Access-Control-Allow-Credentials' 'true' always;

      add_header 'Access-Control-Expose-Headers' 'satoken' always;

    }

  }

}
```